---
sidebar_position: 3
---

# آئیزک آر او ایس ادراک پائپ لائن (Isaac ROS Perception Pipeline)

ایک بار جب ہمارے پاس ایک طاقتور سیمولیٹر اور اے آئی (AI) ماڈلز کی تربیت کا طریقہ موجود ہو، تو ہمیں ان ماڈلز کو روبوٹ پر مؤثر طریقے سے چلانے کے لیے ایک راستے کی ضرورت ہوتی ہے۔ یہیں **Isaac ROS** کا کردار شروع ہوتا ہے۔ آئیزک آر او ایس اعلیٰ کارکردگی والے، ہارڈ ویئر ایکسلریٹڈ (hardware-accelerated) ROS 2 پیکجز کا مجموعہ ہے جو آپ کے روبوٹ کے ادراک کے نظام (perception system) کے بنیادی بلاکس بناتے ہیں۔

یہ پیکجز خاص طور پر NVIDIA GPUs کی طاقت کا فائدہ اٹھانے کے لیے ڈیزائن کیے گئے ہیں، جو پیچیدہ اے آئی کاموں کی ریئل ٹائم پروسیسنگ کو ممکن بناتے ہیں جو کہ سی پی یو (CPU) پر ناممکن ہوتے۔ یہ معیاری ROS 2 پیکجز کے طور پر جاری کیے گئے ہیں، جس کا مطلب ہے کہ یہ آپ کے موجودہ ROS 2 ورک اسپیس میں بغیر کسی رکاوٹ کے ضم ہو جاتے ہیں۔ آپ انہیں `ros2 launch` کر سکتے ہیں، ان کے ٹاپکس کو ری میپ (remap) کر سکتے ہیں، اور کسی بھی دوسرے نوڈ کی طرح `rqt` کے ذریعے ان کا معائنہ کر سکتے ہیں۔

آئیے کچھ اہم اجزاء پر نظر ڈالتے ہیں جنہیں آپ ہیومنائیڈ روبوٹ کے لیے ادراک کی پائپ لائن (perception pipeline) بنانے کے لیے استعمال کر سکتے ہیں۔

### وی سلیم: نیویگیشن کے لیے بصری سلیم (VSLAM: Visual SLAM)

**VSLAM (Visual Simultaneous Localization and Mapping)** جدید خود مختار نیویگیشن کا سنگِ میل ہے۔ یہ روبوٹ کو ایک نامعلوم ماحول کا نقشہ بنانے کی اجازت دیتا ہے اور ساتھ ہی اس نقشے کے اندر اپنی پوزیشن کو ٹریک کرنے کے قابل بناتا ہے، اور اس کے لیے وہ صرف کیمروں سے حاصل کردہ ان پٹ استعمال کرتا ہے۔



آئیزک آر او ایس سوٹ میں ایک انتہائی بہتر بنایا گیا VSLAM پیکج شامل ہے۔ یہ سنکرونائزڈ اسٹیریو کیمرہ امیجز اور IMU ڈیٹا کو ان پٹ کے طور پر لیتا ہے اور دو اہم آؤٹ پٹس پیدا کرتا ہے:
1. **پوز (Pose):** روبوٹ کی تخمینہ شدہ پوزیشن اور رخ (`tf` اور `nav_msgs/msg/Odometry`)۔ یہ جاننے کے لیے ضروری ہے کہ روبوٹ کہاں ہے۔
2. **نقشہ (Map):** ماحول کا تھری ڈی پوائنٹ کلاؤڈ میپ (`sensor_msgs/msg/PointCloud2`)۔ اسے نیویگیشن سسٹم پاتھ پلاننگ کے لیے استعمال کرتا ہے۔

VSLAM کے شدید کمپیوٹیشنل بوجھ کو جی پی یو (GPU) پر منتقل کر کے، آئیزک آر او ایس پیکج ریئل ٹائم کارکردگی حاصل کر سکتا ہے، جو ایک متحرک ہیومنائیڈ روبوٹ کے لیے بہت اہم ہے تاکہ وہ اپنے گردونواح پر تیزی سے ردعمل دے سکے۔

### اشیاء کی شناخت اور سیگمنٹیشن نوڈس (Object Detection & Segmentation Nodes)

ایک روبوٹ کو صرف رکاوٹوں سے بچنے سے زیادہ کام کرنے کی ضرورت ہوتی ہے؛ اسے سمجھنے کی ضرورت ہوتی ہے کہ وہ رکاوٹیں **کیا** ہیں۔ آئیزک آر او ایس عام ادراک کے کاموں کے لیے پہلے سے بنے ہوئے نوڈس فراہم کرتا ہے:

* **آبجیکٹ ڈیٹیکشن (Object Detection):** اس میں تصویر میں اشیاء کی شناخت کرنا اور ان کے گرد ایک باؤنڈنگ باکس بنانا شامل ہے۔ آئیزک آر او ایس کا `isaac_ros_detectnet` پیکج ایک ایسا نوڈ فراہم کرتا ہے جو پہلے سے تربیت یافتہ ڈیٹیکشن ماڈل (جیسے DetectNet یا YOLO) کو ہائی فریم ریٹس پر چلا سکتا ہے۔ آپ آئیزک سم کے مصنوعی ڈیٹا پر اپنا ماڈل ٹرین کر کے اسے اس نوڈ کے ذریعے استعمال کر سکتے ہیں۔



* **سیگمنٹیشن (Segmentation):** یہ ادراک کی ایک زیادہ تفصیلی شکل ہے جہاں تصویر کے ہر پکسل کی درجہ بندی کی جاتی ہے۔
    * **سیمنٹک سیگمنٹیشن (Semantic Segmentation):** ہر پکسل کو ایک زمرے میں تقسیم کرتا ہے (مثلاً "کرسی"، "فرش"، "دیوار")۔ اس کے لیے `isaac_ros_unet` پیکج استعمال کیا جا سکتا ہے۔
    * **انسٹنس سیگمنٹیشن (Instance Segmentation):** یہ ایک قدم آگے جاتا ہے اور ایک ہی زمرے کی مختلف اشیاء کے درمیان فرق کرتا ہے (مثلاً "کرسی 1"، "کرسی 2")۔

### جی پی یو ایکسلریشن کا جائزہ (GPU Acceleration Overview)

آئیزک آر او ایس کے پیچھے اصل جادو **GPU ایکسلریشن** ہے۔ ڈیپ لرننگ انفرنس (آبجیکٹ ڈیٹیکشن کے لیے) اور فیچر میچنگ (VSLAM کے لیے) جیسے کام وسیع پیمانے پر متوازی (parallel) مسائل ہیں، جو انہیں جی پی یو کے فنِ تعمیر کے لیے بالکل موزوں بناتے ہیں۔



آئیزک آر او ایس کی ادراک پائپ لائن کا ایک سادہ بلاک ڈایاگرام کچھ یوں ہے:

[اسٹیریو کیمرہ + IMU] ----> [آئیزک آر او ایس VSLAM نوڈ] ----> [پوز (TF) اور نقشہ (PointCloud2)] | |----> [درست اسٹیریو تصاویر] ----> [آئیزک آر او ایس DetectNet نوڈ] ----> [شناخت شدہ اشیاء کے باؤنڈنگ باکسز]


اس پائپ لائن میں:
1. کیمروں اور IMU سے خام سینسر ڈیٹا سسٹم میں داخل ہوتا ہے۔
2. VSLAM نوڈ تصاویر اور IMU ڈیٹا کو پروسیس کرنے کے لیے جی پی یو پر چلتا ہے، اور مسلسل روبوٹ کے پوز اور نقشے کو اپ ڈیٹ کرتا رہتا ہے۔
3. اسی وقت، درست (rectified) اسٹیریو تصاویر DetectNet نوڈ کو بھیجی جاتی ہیں۔ ڈیپ لرننگ ماڈل جی پی یو کے Tensor Cores پر چلایا جاتا ہے، جس سے وہ VSLAM کے عمل کو سست کیے بغیر ریئل ٹائم میں اشیاء کی شناخت کر سکتا ہے۔
4. تمام آؤٹ پٹس—پوز، میپ، اور آبجیکٹ ڈیٹیکشن—معیاری ROS 2 میسجز کے طور پر پبلش کیے جاتے ہیں، جو روبوٹ کے نیویگیشن اور فیصلہ سازی کے نظام کے استعمال کے لیے تیار ہوتے ہیں۔

یہ پوری پائپ لائن، جو صرف سی پی یو والے سسٹم کو مفلوج کر سکتی ہے، NVIDIA Jetson Orin یا ایک ڈیسک ٹاپ جی پی یو پر مؤثر طریقے سے چل سکتی ہے۔ یہی وہ کارکردگی ہے جو ہیومنائیڈ روبوٹس جیسے پیچیدہ پلیٹ فارمز کے لیے اے آئی پر مبنی خود مختاری کو ممکن بناتی